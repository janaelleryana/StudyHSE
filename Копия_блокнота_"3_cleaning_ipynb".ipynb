{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaelleryana/StudyHSE/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%223_cleaning_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning** (чистка данных) - этап предварительной обработки данных для анализа данных и машинного обучения.\n",
        "\n",
        "**Примеры Data Cleaning:**\n",
        "- удаление избыточных столбцов из табличных данных;\n",
        "- приведение текста к нижнему регистру;\n",
        "- чистка текста от HTML-артефактов\n",
        "\n",
        "Загрузим тренировочный датасет, почистим его и проанализируем результаты."
      ],
      "metadata": {
        "id": "Vl6M3rDU5XhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1: Загрузка данных\n",
        "\n",
        "Загрузим тренировочный датасет и посмотрим на наши данные.\n",
        "\n",
        "Представим, что мы загрузили статью в формате HTML.\n",
        "\n",
        "Скачаем ее и выведем на экран первые 100 символов с помощью слайсинга (среза)."
      ],
      "metadata": {
        "id": "LK_zsNv26Tsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем тренировочные данные\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbak8zIx8i6_",
        "outputId": "ef0a0bd4-9a25-49e6-ed2a-819f0e6c697b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 11:09:59--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2377 (2.3K) [text/plain]\n",
            "Saving to: ‘data_cleaning.txt’\n",
            "\n",
            "data_cleaning.txt   100%[===================>]   2.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 11:10:00 (29.1 MB/s) - ‘data_cleaning.txt’ saved [2377/2377]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную data\n",
        "with open('data_cleaning.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "OJ68oc8E8r9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выведите на экран первые 100 символов с помощью слайсинга\n",
        "\n",
        "html_content = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Sample HTML Document</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Welcome to Data Cleaning</h1>\n",
        "    <p>This is a sample paragraph with <b>HTML artifacts</b> such as <i>bold</i> and <u>italic</u> text. Data cleaning is an essential process in preparing data for analysis. It involves various techniques to clean, transform, and preprocess data.</p>\n",
        "    <p>In data cleaning, it's important to remove <em>stop words</em> like \"the\", \"and\", \"of\", etc. Stop words are common words that are often filtered out from text data because they do not carry significant meaning.</p>\n",
        "    <p>Here's another paragraph. Sometimes text is in <strong>UPPERCASE</strong> or <em>lowercase</em>. It's important to standardize the text case to ensure consistency in the dataset. This can be achieved by converting all text to lowercase or uppercase.</p>\n",
        "    <p>It's crucial to handle <code>HTML entities</code> such as <div>, <p>, &amp;, etc. HTML entities are special characters or symbols that have specific meanings in HTML. They need to be properly handled to avoid issues during data processing.</p>\n",
        "    <p>Data cleaning also involves dealing with missing values. Missing values can occur due to various reasons such as incomplete data collection or data entry errors. It's essential to identify and handle missing values appropriately to avoid bias in the analysis.</p>\n",
        "    <p>Text data often contains noise such as punctuation marks, special characters, and digits. Removing noise from text data is necessary to focus on the meaningful content. Techniques such as regular expressions can be used for noise removal.</p>\n",
        "    <p>Another important aspect of data cleaning is deduplication. Duplicate records in a dataset can skew analysis results and lead to inaccurate conclusions. Identifying and removing duplicate records ensures data integrity and improves the quality of analysis.</p>\n",
        "    <p>After cleaning the data, it's essential to perform exploratory data analysis (EDA) to gain insights and identify patterns. EDA involves visualizing data, computing summary statistics, and exploring relationships between variables.</p>\n",
        "    <p>Once the data is cleaned and analyzed, it can be used for various purposes such as building machine learning models, making predictions, or generating insights to support decision-making processes.</p>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "# Записываем в файл (опционально, для теста)\n",
        "with open('data_cleaning.txt', 'w') as f:\n",
        "    f.write(html_content)\n",
        "\n",
        "# Теперь читаем и выводим первые 100 символов\n",
        "with open('data_cleaning.txt', 'r') as f:\n",
        "    data = f.read()\n",
        "\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ9GtP8s86V8",
        "outputId": "7c24ecb9-d574-4eaf-a410-7d38e7d2c39b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Sample HTML Document</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Welcome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2: Удаление артефактов\n",
        "\n",
        "В данных много артефактов - HTML-тегов.\n",
        "\n",
        "Удалим HTML-артефакты с помощью регулярных выражений RegEx"
      ],
      "metadata": {
        "id": "XIGQ9xGQ6t1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# пропишем паттерн для поиска HTML-тегов вида <tag> ... </tag>\n",
        "import re   # загрузим библиотеку для обработки регулярных выражений\n",
        "\n",
        "tag_pattern = r'<[^>]+>'    # паттерн для поиска тегов"
      ],
      "metadata": {
        "id": "aQ0ka1oq9uVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используйте функцию `re.sub` (substitution) для чистки данных\n",
        "\n",
        "`re.sub` ищет в строке `string` соответствия RegEx-паттерну `pattern` и меняет найденное на указанную строку `repl`\n",
        "\n",
        "Как используем функцию: `re.sub(pattern, repl, string)`\n",
        "\n",
        "- `pattern` - паттерн RegEx, соответствия которому будет искать функция\n",
        "- `repl` - на что будем менять найденные соответствия\n",
        "- `string` - где будем искать, наш датасет\n",
        "\n",
        "Запишите результат в переменную `clean_text` и выведите на экран с 720-го по 800-ый символ очищенного текста\n",
        "\n",
        "Используйте слайсинг"
      ],
      "metadata": {
        "id": "h8oleHAo_UaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсказки:\n",
        "# используйте паттерн, записанный в переменную tag_pattern\n",
        "# замените результат на пустую строку \"\"\n",
        "# Предполагается, что переменная `data` уже содержит HTML-текст (например, из файла data_cleaning.txt)\n",
        "\n",
        "import re\n",
        "\n",
        "# Шаг 1: Удаление HTML-тегов\n",
        "tag_pattern = r'<[^>]+>'\n",
        "clean_text = re.sub(tag_pattern, \"\", data)\n",
        "\n",
        "# Вывод с 720-го по 800-й символ\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjqjGi8P-H6O",
        "outputId": "4ab3f454-3917-434b-8226-e4758c8c28d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as , , &amp;, etc. HTML entities are \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы удалили не все специальные символы HTML\n",
        "\n",
        "Создадим еще один паттерн и повторим процедуру"
      ],
      "metadata": {
        "id": "fZAWGBC7Ajr7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XN3_m_xY39_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_pattern = r'&\\w+;'    # паттерн для поиска специальных символов"
      ],
      "metadata": {
        "id": "jIftruIgBuQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используйте `re.sub` для удаления этих символов\n",
        "\n",
        "Теперь функция принимает на вход паттерн `symbols_pattern` и текст `clean_text`\n",
        "\n",
        "Перезапишите переменную `clean_text`\n",
        "\n",
        "Выведите на экран с 720-го по 800-ый символ, чтобы убедиться в том, что чистка прошла успешно"
      ],
      "metadata": {
        "id": "LJ19ehiFB5d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_pattern = r'&\\w+;'\n",
        "clean_text = re.sub(symbols_pattern, \"\", clean_text)\n",
        "\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsX39hWDCLR6",
        "outputId": "70dc3226-49a5-4258-901a-712bf7b02cb6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as , , , etc. HTML entities are speci\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В нашем тексте остались двойные пробелы\n",
        "\n",
        "Уберем им с помощью очередного паттерна"
      ],
      "metadata": {
        "id": "mP70Rf3oCKNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text[:100]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GMGJDpaEDHx5",
        "outputId": "9bee1f93-ccd3-45cc-9877-4d0c0372cfba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sample HTML Document Welcome to Data Cleaning This is a sample paragraph with HTML artifacts such a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем паттерн для поиска двойных пробелов\n",
        "\n",
        "Повторите процедуру, перезапишите результат в `clean_text` и выведите первые 100 символов\n",
        "\n",
        "Что мы запишем в переменную `repl`, чтобы не удалить абсолютно все пробелы?"
      ],
      "metadata": {
        "id": "GpgXBzMxDicX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_pattern = r'\\s+'\n",
        "\n",
        "clean_text = re.sub(space_pattern, \" \", clean_text)\n",
        "\n",
        "clean_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aQ-ZqbEcDcIE",
        "outputId": "e7968a8f-e2db-45be-d64d-c071e7ec91b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sample HTML Document Welcome to Data Cleaning This is a sample paragraph with HTML artifacts such a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3: Смена регистра\n",
        "\n",
        "Приведем все слова к нижнему регистру с помощью функции `lower`\n",
        "\n",
        "Запишем результат в переменную `text_lower` и выведем на экран последние 100 символов"
      ],
      "metadata": {
        "id": "Hwtj4l2x6bwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Приведение всего текста к нижнему регистру\n",
        "text_lower = clean_text.lower()\n",
        "\n",
        "# Вывод последних 100 символов\n",
        "text_lower[-100:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NbmH8JL0EPeg",
        "outputId": "2cc3823b-af3d-45a7-de42-25c428b8743c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e learning models, making predictions, or generating insights to support decision-making processes. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4: Удаление стоп-слов\n",
        "\n",
        "Удалим частотные слова, которые создают шум для решения задач\n",
        "\n",
        "Загрузим список стоп-слов"
      ],
      "metadata": {
        "id": "vkxdtN1Q6mwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ypsKpKBE6T-",
        "outputId": "feea762c-2265-4b84-c620-26883d3e6277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 11:47:14--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 954 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "\rstopwords.txt         0%[                    ]       0  --.-KB/s               \rstopwords.txt       100%[===================>]     954  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 11:47:15 (39.3 MB/s) - ‘stopwords.txt’ saved [954/954]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите на экран первые 10 стоп-слов"
      ],
      "metadata": {
        "id": "nansznnrFVN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную stopwords\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()"
      ],
      "metadata": {
        "id": "O5m3KmZW84Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
        "\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()\n",
        "  print(stopwords[:10])"
      ],
      "metadata": {
        "id": "_c1xfdkgFNcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa8bfb2-2ad8-49a3-87f3-8e78a22dd8da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 08:06:55--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 954 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "\rstopwords.txt         0%[                    ]       0  --.-KB/s               \rstopwords.txt       100%[===================>]     954  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-22 08:06:55 (42.0 MB/s) - ‘stopwords.txt’ saved [954/954]\n",
            "\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью `random` мы можем \"вытянуть\" из списка стоп-слов случайное слово"
      ],
      "metadata": {
        "id": "7C4R5y63Fqrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.choice(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8SX-lcCAFjNc",
        "outputId": "17cbf459-c66d-4b7a-b172-ad487fdc4d0d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yours'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Вытяните\" еще одно случайное слово и запишите его в переменную `random_word`"
      ],
      "metadata": {
        "id": "tPDPQYYTFwsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_word = random.choice(stopwords)"
      ],
      "metadata": {
        "id": "oJkDb27LF75t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Выбор случайного стоп-слова\n",
        "random_word = random.choice(stopwords)"
      ],
      "metadata": {
        "id": "PAVezQqC-SOJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверьте, есть ли это слово в `text_lower` с помощью `in`\n",
        "\n",
        "Выведите на экран это слово"
      ],
      "metadata": {
        "id": "erv_tjszGZlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Результат проверки:\", random_word in text_lower)\n",
        "print(\"Случайное слово:\", random_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2NJtaSOGBDT",
        "outputId": "d2ffbe16-c62b-429f-ffd2-dc6d91c33f7c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат проверки: False\n",
            "Случайное слово: been\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте сгенерировать еще несколько слов и проверить их наличие в `text_lower`\n",
        "\n",
        "Для этого запустите повторно две последние ячейки"
      ],
      "metadata": {
        "id": "VBJJHLvrHCCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Вот так будет выглядеть текст после удаления стоп-слов _без_ токенизации\n",
        "Заменятся все аналогичные сочетания знаков\n",
        "Поэтому перед _удалением_ стоп-слов, проведем токенизацию\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gY7oeXTXGW0D",
        "outputId": "ae290a00-6368-4dfa-d11a-9eba63f7434f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nВот так будет выглядеть текст после удаления стоп-слов _без_ токенизации\\nЗаменятся все аналогичные сочетания знаков\\nПоэтому перед _удалением_ стоп-слов, проведем токенизацию\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 5: Токенизация\n",
        "\n",
        "Токенизируем датасет для дальнейшей работы\n",
        "\n",
        "Создадим 2 набора токенов: с сегментацией по предложениям и с сегментацией по словам"
      ],
      "metadata": {
        "id": "Mepvb0Kw7Ncq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте переменную `sentences`\n",
        "\n",
        "С помощью `split` разделите текст на предложения (сегменты, разделенные знаком `.`)\n",
        "\n",
        "Выведите на экран первые 10 элементов `sentences`"
      ],
      "metadata": {
        "id": "Me63a7SNLa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ваш код здесь: split для сегментации по знаку `.` ###\n",
        "### вывод на экран первых 10 предложений ###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G13fM_27M1t",
        "outputId": "5238ef6b-7c2d-4bc2-e052-28d263da20ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' sample html document welcome to data cleaning this is a sample paragraph with html artifacts such as bold and italic text',\n",
              " ' data cleaning is an essential process in preparing data for analysis',\n",
              " ' it involves various techniques to clean, transform, and preprocess data',\n",
              " ' in data cleaning, it\\'s important to remove stop words like \"the\", \"and\", \"of\", etc',\n",
              " ' stop words are common words that are often filtered out from text data because they do not carry significant meaning',\n",
              " \" here's another paragraph\",\n",
              " ' sometimes text is in uppercase or lowercase',\n",
              " \" it's important to standardize the text case to ensure consistency in the dataset\",\n",
              " ' this can be achieved by converting all text to lowercase or uppercase',\n",
              " \" it's crucial to handle html entities such as div, p, , etc\"]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте переменную `tokens`\n",
        "\n",
        "С помощью `split` разделите текст `text_lower` на слова\n",
        "\n",
        "Выведите первые 10 элементов"
      ],
      "metadata": {
        "id": "6J_C8cq0L2rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_lower.split('.')\n",
        "\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj3dXh576a5A",
        "outputId": "6f7f843a-9c20-4796-879b-9ad03be682e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' sample html document welcome to data cleaning this is a sample paragraph with html artifacts such as bold and italic text',\n",
              " ' data cleaning is an essential process in preparing data for analysis',\n",
              " ' it involves various techniques to clean, transform, and preprocess data',\n",
              " ' in data cleaning, it\\'s important to remove stop words like \"the\", \"and\", \"of\", etc',\n",
              " ' stop words are common words that are often filtered out from text data because they do not carry significant meaning',\n",
              " \" here's another paragraph\",\n",
              " ' sometimes text is in uppercase or lowercase',\n",
              " \" it's important to standardize the text case to ensure consistency in the dataset\",\n",
              " ' this can be achieved by converting all text to lowercase or uppercase',\n",
              " \" it's crucial to handle html entities such as , , , etc\"]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Удалим стоп-слова"
      ],
      "metadata": {
        "id": "5Q7FfNK9MJ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text_lower.split()\n",
        "tokens[:10]  # показать первые 10 слов\n",
        "\n",
        "clean_tokens = []\n",
        "for token in tokens:\n",
        "    if token not in stopwords:  # ← здесь была ошибка: было \"tokens\", нужно \"token\"\n",
        "        clean_tokens.append(token)\n",
        "\n",
        "clean_tokens[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMy-_DNJ0HF3",
        "outputId": "9ec5a424-d80b-4727-a353-778adad85db0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample',\n",
              " 'html',\n",
              " 'document',\n",
              " 'welcome',\n",
              " 'data',\n",
              " 'cleaning',\n",
              " 'sample',\n",
              " 'paragraph',\n",
              " 'html',\n",
              " 'artifacts']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# И еще одно задание...\n",
        "\n",
        "В ячейке ниже вы сможете загрузить еще один текст\n",
        "\n",
        "Используйте свой код и код из задания, чтобы\n",
        "\n",
        "1. удалить артефакты (html-теги, специальные символы и двойные пробелы)\n",
        "\n",
        "2. привести текст к нижнему регистру\n",
        "\n",
        "3. токенизировать текст по предложениям\n",
        "\n",
        "4. токенизировать текст по словам\n",
        "\n",
        "5. удалить стоп-слова"
      ],
      "metadata": {
        "id": "0EYfMpHZNUkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE6b-OKsNqK_",
        "outputId": "4735ce90-f57f-44b7-90e3-e091005413b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 12:26:33--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 845 [text/plain]\n",
            "Saving to: ‘artefacts.txt’\n",
            "\n",
            "\rartefacts.txt         0%[                    ]       0  --.-KB/s               \rartefacts.txt       100%[===================>]     845  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-25 12:26:33 (30.2 MB/s) - ‘artefacts.txt’ saved [845/845]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную artefacts\n",
        "with open('artefacts.txt', 'r') as f:\n",
        "  artefacts = f.read()"
      ],
      "metadata": {
        "id": "CT7eVLpHOMTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка нового текста\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt\n",
        "\n",
        "with open('artefacts.txt', 'r') as f:\n",
        "    artefacts = f.read()\n",
        "\n",
        "# 1. Удаление артефактов: HTML-теги, специальные символы, двойные пробелы\n",
        "import re\n",
        "\n",
        "# Удаляем HTML-теги\n",
        "clean_text = re.sub(r'<[^>]+>', '', artefacts)\n",
        "\n",
        "# Удаляем HTML-сущности (<, &amp; и т.д.)\n",
        "clean_text = re.sub(r'&\\w+;', '', clean_text)\n",
        "\n",
        "# Заменяем любые последовательности пробельных символов на один пробел\n",
        "clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
        "\n",
        "# 2. Приведение к нижнему регистру\n",
        "text_lower = clean_text.lower()\n",
        "\n",
        "# 3. Токенизация по предложениям (разделение по точке)\n",
        "sentences = text_lower.split('.')\n",
        "\n",
        "# 4. Токенизация по словам\n",
        "tokens = text_lower.split()\n",
        "\n",
        "# 5. Удаление стоп-слов (предполагается, что `stopwords` уже загружены из предыдущего задания)\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()\n",
        "\n",
        "# Фильтрация токенов\n",
        "clean_tokens = [token for token in tokens if token not in stopwords]"
      ],
      "metadata": {
        "id": "9g-geUOsORlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378fc60e-cd02-4556-c53e-2a782fa0e705"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 08:30:12--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 845 [text/plain]\n",
            "Saving to: ‘artefacts.txt.1’\n",
            "\n",
            "\rartefacts.txt.1       0%[                    ]       0  --.-KB/s               \rartefacts.txt.1     100%[===================>]     845  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-22 08:30:12 (66.9 MB/s) - ‘artefacts.txt.1’ saved [845/845]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}