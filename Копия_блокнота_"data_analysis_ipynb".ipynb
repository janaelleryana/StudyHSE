{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vrtdr5UF_TyT",
        "JLaq0LFXBBI9",
        "vSc5RUhgBu_3",
        "aptZI3yhEOlW",
        "WvPQoLBzGvAS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaelleryana/StudyHSE/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22data_analysis_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1: выгрузка файлов"
      ],
      "metadata": {
        "id": "aa2G_JERA7yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ],
      "metadata": {
        "id": "vrtdr5UF_TyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "a979d2eb-896f-4223-cce8-cb09ff4d6903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:46--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "\rtwitter.txt           0%[                    ]       0  --.-KB/s               \rtwitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-12-04 13:14:46 (31.1 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ],
      "metadata": {
        "id": "kekDrEGyAXUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt -O BNCCorpus.txt"
      ],
      "metadata": {
        "id": "1FAveoWrAWm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254df1b6-bf4a-46ef-e85a-7caf58350ae4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:46--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19081694 (18M) [text/plain]\n",
            "Saving to: ‘BNCCorpus.txt’\n",
            "\n",
            "BNCCorpus.txt       100%[===================>]  18.20M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-12-04 13:14:46 (228 MB/s) - ‘BNCCorpus.txt’ saved [19081694/19081694]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt -O MovieCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJKMZZD5XRHe",
        "outputId": "af3f89a4-aeb1-4cde-9088-678cbed00013"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:46--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976724 (16M) [text/plain]\n",
            "Saving to: ‘MovieCorpus.txt’\n",
            "\n",
            "MovieCorpus.txt     100%[===================>]  16.19M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-12-04 13:14:46 (224 MB/s) - ‘MovieCorpus.txt’ saved [16976724/16976724]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt -O bncsplitword.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy1WW2FZXer4",
        "outputId": "0b214881-d033-42f4-ae52-12ae629126eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:46--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173003 (18M) [text/plain]\n",
            "Saving to: ‘bncsplitword.txt’\n",
            "\n",
            "bncsplitword.txt    100%[===================>]  18.28M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-12-04 13:14:46 (265 MB/s) - ‘bncsplitword.txt’ saved [19173003/19173003]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt -O TwitterConvCorpus.txt"
      ],
      "metadata": {
        "id": "T8ZpnmH4a4Mt",
        "outputId": "956072fe-abed-48ef-8cee-b04db28a8a55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:47--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612338 (598K) [text/plain]\n",
            "Saving to: ‘TwitterConvCorpus.txt’\n",
            "\n",
            "\rTwitterConvCorpus.t   0%[                    ]       0  --.-KB/s               \rTwitterConvCorpus.t 100%[===================>] 597.99K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-12-04 13:14:47 (31.3 MB/s) - ‘TwitterConvCorpus.txt’ saved [612338/612338]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67531b1-583c-4bdf-b7ad-c2f762be7a57",
        "id": "TLa2CPFAbNMF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 13:14:47--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "\rtwitter.txt           0%[                    ]       0  --.-KB/s               \rtwitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-12-04 13:14:47 (29.8 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2: открываем файлы"
      ],
      "metadata": {
        "id": "JLaq0LFXBBI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ],
      "metadata": {
        "id": "AjNtW5R1BI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "3f13026f-83e2-47c6-9aa8-d413a0827d75"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: откройте все файлы, выведите на экран их размер и первые 100 символов (всего должно быть обработано 5 файлов)"
      ],
      "metadata": {
        "id": "yrYxdTj6BGv_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('TwitterConvCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "id": "tAOeQqM4bbtT",
        "outputId": "5fdf1c8d-e36b-4498-bb7f-c7efc53fe46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 598556 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on Twitter? Haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('bncsplitword.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "kuCdxgHCbkV6",
        "outputId": "fd5ae3bb-7ce4-4392-e6fb-c5362b2616b3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19173003 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice trip yes\\nOh very good\\nsaw Mary and An'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('MovieCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "outputId": "40ff528c-647a-4fc3-a424-6687c01ef630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "U1wZWeKjcKzg"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 16976724 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\\nGood ones, yes, Mr Vereke\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('BNCCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "outputId": "051600f3-91d5-4d26-e978-f8e553e9e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "kMeSH1vRcJ_f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19081694 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice tripyes\\nOh very good\\nsaw Mary and And'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7b346357-6526-49c8-cde9-8a20f0f08b78",
        "id": "h-38OyXicaoB"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3: первичный анализ"
      ],
      "metadata": {
        "id": "vSc5RUhgBu_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ],
      "metadata": {
        "id": "ui-vA_4wB76-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('twitter.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "total_lines = len(lines)\n",
        "non_empty_lines = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "\n",
        "line_lengths = []\n",
        "\n",
        "for line in lines:\n",
        "    stripped_line = line.rstrip('\\n\\r')\n",
        "    line_len = len(stripped_line)\n",
        "    line_lengths.append(line_len)\n",
        "\n",
        "    total_chars += line_len\n",
        "    words_in_line = stripped_line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line_len > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "if line_lengths:\n",
        "    max_line_length = max(line_lengths)\n",
        "    min_line_length = min(line_lengths)\n",
        "else:\n",
        "    max_line_length = 0\n",
        "    min_line_length = 0\n",
        "\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "id": "XliSd4K4Byym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94beb2fd-a958-4e29-be80-8c8800ebae37"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('BNCCorpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "total_lines = len(lines)\n",
        "non_empty_lines = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "\n",
        "line_lengths = []\n",
        "\n",
        "for line in lines:\n",
        "    stripped_line = line.rstrip('\\n\\r')\n",
        "    line_len = len(stripped_line)\n",
        "    line_lengths.append(line_len)\n",
        "\n",
        "    total_chars += line_len\n",
        "    words_in_line = stripped_line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line_len > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "if line_lengths:\n",
        "    max_line_length = max(line_lengths)\n",
        "    min_line_length = min(line_lengths)\n",
        "else:\n",
        "    max_line_length = 0\n",
        "    min_line_length = 0\n",
        "\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05761e6-da1c-4a7b-91fc-733a62963624",
        "id": "nysfmRZ5fsqs"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 3719853\n",
            "Всего символов: 18470680\n",
            "Макс. длина строки: 2702\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('MovieCorpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "total_lines = len(lines)\n",
        "non_empty_lines = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "\n",
        "line_lengths = []\n",
        "\n",
        "for line in lines:\n",
        "    stripped_line = line.rstrip('\\n\\r')\n",
        "    line_len = len(stripped_line)\n",
        "    line_lengths.append(line_len)\n",
        "\n",
        "    total_chars += line_len\n",
        "    words_in_line = stripped_line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line_len > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "if line_lengths:\n",
        "    max_line_length = max(line_lengths)\n",
        "    min_line_length = min(line_lengths)\n",
        "else:\n",
        "    max_line_length = 0\n",
        "    min_line_length = 0\n",
        "\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7a5cb1-1cd3-43b6-8cfe-5fab67a98ebb",
        "id": "Udqc51TSfsPi"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 304713\n",
            "Непустых строк: 304713\n",
            "Всего слов: 3185395\n",
            "Всего символов: 16672011\n",
            "Макс. длина строки: 3039\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bncsplitword.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "total_lines = len(lines)\n",
        "non_empty_lines = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "\n",
        "line_lengths = []\n",
        "\n",
        "for line in lines:\n",
        "    stripped_line = line.rstrip('\\n\\r')\n",
        "    line_len = len(stripped_line)\n",
        "    line_lengths.append(line_len)\n",
        "\n",
        "    total_chars += line_len\n",
        "    words_in_line = stripped_line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line_len > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "if line_lengths:\n",
        "    max_line_length = max(line_lengths)\n",
        "    min_line_length = min(line_lengths)\n",
        "else:\n",
        "    max_line_length = 0\n",
        "    min_line_length = 0\n",
        "\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81fc9263-fe36-4d57-d4ee-bd000243cfc2",
        "id": "qvG3siyafrvL"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 4052241\n",
            "Всего символов: 18561989\n",
            "Макс. длина строки: 2773\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('TwitterConvCorpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "total_lines = len(lines)\n",
        "non_empty_lines = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "\n",
        "line_lengths = []\n",
        "\n",
        "for line in lines:\n",
        "    stripped_line = line.rstrip('\\n\\r')\n",
        "    line_len = len(stripped_line)\n",
        "    line_lengths.append(line_len)\n",
        "\n",
        "    total_chars += line_len\n",
        "    words_in_line = stripped_line.split()\n",
        "    total_words += len(words_in_line)\n",
        "\n",
        "    if line_len > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "if line_lengths:\n",
        "    max_line_length = max(line_lengths)\n",
        "    min_line_length = min(line_lengths)\n",
        "else:\n",
        "    max_line_length = 0\n",
        "    min_line_length = 0\n",
        "\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f12446-0833-4a29-8ba1-ae05f5e26163",
        "id": "XL3Q4J5sfqmw"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10628\n",
            "Всего слов: 114910\n",
            "Всего символов: 582000\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4: чистка текста"
      ],
      "metadata": {
        "id": "aptZI3yhEOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('twitter.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Удаляем внешние пробелы и символы новой строки\n",
        "    stripped_line = line.strip()\n",
        "\n",
        "    # 2. Оставляем только буквы, цифры и пробелы (все остальное заменяем на пробел)\n",
        "    #    Используем регулярное выражение: [^а-яА-Яa-zA-Z0-9\\s] — всё, кроме букв, цифр и пробельных символов\n",
        "    cleaned = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', ' ', stripped_line)\n",
        "\n",
        "    # 3. Заменяем множественные пробелы на один\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    # Сохраняем очищенную строку (даже если она стала пустой)\n",
        "    cleaned_lines.append(cleaned)\n",
        "\n",
        "    # 5. Разбиваем на слова и фильтруем пустые / слишком короткие\n",
        "    words = cleaned.split()\n",
        "    for word in words:\n",
        "        if len(word) >= 1:  # условие \"не короче 1 символа\" — то есть ≥1\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "# Вывод результата\n",
        "if cleaned_lines:\n",
        "    example_line = cleaned_lines[0][:100]\n",
        "else:\n",
        "    example_line = \"\"\n",
        "\n",
        "print(f\"Пример очищенной строки: {example_line}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "c580bbf4-de91-4f54-c1ed-fb8800976bd0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 117699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('MovieCorpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Удаляем внешние пробелы и символы новой строки\n",
        "    stripped_line = line.strip()\n",
        "\n",
        "    # 2. Оставляем только буквы, цифры и пробелы (все остальное заменяем на пробел)\n",
        "    #    Используем регулярное выражение: [^а-яА-Яa-zA-Z0-9\\s] — всё, кроме букв, цифр и пробельных символов\n",
        "    cleaned = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', ' ', stripped_line)\n",
        "\n",
        "    # 3. Заменяем множественные пробелы на один\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    # Сохраняем очищенную строку (даже если она стала пустой)\n",
        "    cleaned_lines.append(cleaned)\n",
        "\n",
        "    # 5. Разбиваем на слова и фильтруем пустые / слишком короткие\n",
        "    words = cleaned.split()\n",
        "    for word in words:\n",
        "        if len(word) >= 1:  # условие \"не короче 1 символа\" — то есть ≥1\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "# Вывод результата\n",
        "if cleaned_lines:\n",
        "    example_line = cleaned_lines[0][:100]\n",
        "else:\n",
        "    example_line = \"\"\n",
        "\n",
        "print(f\"Пример очищенной строки: {example_line}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891a9935-5142-4092-c81f-57603f1d24c7",
        "id": "eFhB2FcGhX30"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: colonel durnford william vereker i hear you ve been seeking officers...\n",
            "Всего очищенных слов: 3394743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('BNCCorpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Удаляем внешние пробелы и символы новой строки\n",
        "    stripped_line = line.strip()\n",
        "\n",
        "    # 2. Оставляем только буквы, цифры и пробелы (все остальное заменяем на пробел)\n",
        "    #    Используем регулярное выражение: [^а-яА-Яa-zA-Z0-9\\s] — всё, кроме букв, цифр и пробельных символов\n",
        "    cleaned = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', ' ', stripped_line)\n",
        "\n",
        "    # 3. Заменяем множественные пробелы на один\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    # Сохраняем очищенную строку (даже если она стала пустой)\n",
        "    cleaned_lines.append(cleaned)\n",
        "\n",
        "    # 5. Разбиваем на слова и фильтруем пустые / слишком короткие\n",
        "    words = cleaned.split()\n",
        "    for word in words:\n",
        "        if len(word) >= 1:  # условие \"не короче 1 символа\" — то есть ≥1\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "# Вывод результата\n",
        "if cleaned_lines:\n",
        "    example_line = cleaned_lines[0][:100]\n",
        "else:\n",
        "    example_line = \"\"\n",
        "\n",
        "print(f\"Пример очищенной строки: {example_line}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cfc949-c521-43ad-f0d8-a9f6c243fcb3",
        "id": "jVgBa0rNhWyi"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3995827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('twitter.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Удаляем внешние пробелы и символы новой строки\n",
        "    stripped_line = line.strip()\n",
        "\n",
        "    # 2. Оставляем только буквы, цифры и пробелы (все остальное заменяем на пробел)\n",
        "    #    Используем регулярное выражение: [^а-яА-Яa-zA-Z0-9\\s] — всё, кроме букв, цифр и пробельных символов\n",
        "    cleaned = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', ' ', stripped_line)\n",
        "\n",
        "    # 3. Заменяем множественные пробелы на один\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    # Сохраняем очищенную строку (даже если она стала пустой)\n",
        "    cleaned_lines.append(cleaned)\n",
        "\n",
        "    # 5. Разбиваем на слова и фильтруем пустые / слишком короткие\n",
        "    words = cleaned.split()\n",
        "    for word in words:\n",
        "        if len(word) >= 1:  # условие \"не короче 1 символа\" — то есть ≥1\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "# Вывод результата\n",
        "if cleaned_lines:\n",
        "    example_line = cleaned_lines[0][:100]\n",
        "else:\n",
        "    example_line = \"\"\n",
        "\n",
        "print(f\"Пример очищенной строки: {example_line}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec244238-31f9-40a8-d0f5-2afb2843b2c2",
        "id": "XDFLLv_ThWMQ"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 117699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('bncsplitword.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Удаляем внешние пробелы и символы новой строки\n",
        "    stripped_line = line.strip()\n",
        "\n",
        "    # 2. Оставляем только буквы, цифры и пробелы (все остальное заменяем на пробел)\n",
        "    #    Используем регулярное выражение: [^а-яА-Яa-zA-Z0-9\\s] — всё, кроме букв, цифр и пробельных символов\n",
        "    cleaned = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', ' ', stripped_line)\n",
        "\n",
        "    # 3. Заменяем множественные пробелы на один\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    # Сохраняем очищенную строку (даже если она стала пустой)\n",
        "    cleaned_lines.append(cleaned)\n",
        "\n",
        "    # 5. Разбиваем на слова и фильтруем пустые / слишком короткие\n",
        "    words = cleaned.split()\n",
        "    for word in words:\n",
        "        if len(word) >= 1:  # условие \"не короче 1 символа\" — то есть ≥1\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "# Вывод результата\n",
        "if cleaned_lines:\n",
        "    example_line = cleaned_lines[0][:100]\n",
        "else:\n",
        "    example_line = \"\"\n",
        "\n",
        "print(f\"Пример очищенной строки: {example_line}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a58ea9-6dfa-493c-e9c6-3595f224c00a",
        "id": "dQiYbXgyg6RP"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 4318802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5: статистика"
      ],
      "metadata": {
        "id": "WvPQoLBzGvAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ],
      "metadata": {
        "id": "Iirxb-yneJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "for word in all_cleaned_words:\n",
        "    length = len(word)\n",
        "    word_lengths.append(length)\n",
        "    total_chars += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "word_length_count = {}\n",
        "for length in word_lengths:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "16a29d67-053d-4c89-a0db-23e9a307289b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 117699\n",
            "Символов после очистки: 451014\n",
            "Распределение длин слов:\n",
            "  1 букв: 12732 слов\n",
            "  2 букв: 20430 слов\n",
            "  3 букв: 25349 слов\n",
            "  4 букв: 25124 слов\n",
            "  5 букв: 12802 слов\n",
            "  6 букв: 7759 слов\n",
            "  7 букв: 6005 слов\n",
            "  8 букв: 3435 слов\n",
            "  9 букв: 2024 слов\n",
            "  10 букв: 1063 слов\n",
            "  11 букв: 491 слов\n",
            "  12 букв: 238 слов\n",
            "  13 букв: 118 слов\n",
            "  14 букв: 51 слов\n",
            "  15 букв: 26 слов\n",
            "  16 букв: 17 слов\n",
            "  17 букв: 10 слов\n",
            "  18 букв: 5 слов\n",
            "  19 букв: 5 слов\n",
            "  20 букв: 5 слов\n",
            "  21 букв: 1 слов\n",
            "  22 букв: 2 слов\n",
            "  23 букв: 2 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 1 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: частотность слов"
      ],
      "metadata": {
        "id": "gFZj9nmSeSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "for word in all_cleaned_words:\n",
        "    if word in word_frequency:\n",
        "        word_frequency[word] += 1\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Формируем список кортежей (частотность, слово)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы (по убыванию частоты)\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "# Выводим топ-10\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12uZ3UlLDSJv",
        "outputId": "1cd89cc0-0c4e-469b-cb71-ca55a70e98bf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 5317 раз\n",
            "  2. 'the': 2928 раз\n",
            "  3. 'to': 2579 раз\n",
            "  4. 'you': 2564 раз\n",
            "  5. 'it': 2075 раз\n",
            "  6. 'a': 2066 раз\n",
            "  7. 'and': 1668 раз\n",
            "  8. 'that': 1450 раз\n",
            "  9. 's': 1390 раз\n",
            "  10. 't': 1347 раз\n",
            "\n",
            "Всего уникальных слов: 10801\n"
          ]
        }
      ]
    }
  ]
}